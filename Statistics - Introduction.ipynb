{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Statistics for Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"images/datatypes.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Data\n",
    "\n",
    "-------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "Categorical data represents characteristics. Therefore it can represent things like a person’s gender, language etc. Categorical data can also take on numerical values (Example: 1 for female and 0 for male). Note that those numbers don’t have mathematical meaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nominal Data\n",
    "Nominal values represent discrete units and are used to label variables, that have no quantitative value. Just think of them as „labels“. Note that nominal data that has no order. Therefore if you would change the order of its values, the meaning would not change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordinal Data\n",
    "Ordinal values represent discrete and ordered units. It is therefore nearly the same as nominal data, except that it’s ordering matters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical Data\n",
    "\n",
    "-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discrete Data\n",
    "\n",
    "We speak of discrete data if its values are distinct and separate. In other words: We speak of discrete data if the data can only take on certain values. This type of data can’t be measured but it can be counted. It basically represents information that can be categorized into a classification. An example is the number of heads in 100 coin flips."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuous Data\n",
    "Continuous Data represents measurements and therefore their values can’t be counted but they can be measured. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Measures of Central Tendency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean\n",
    "\n",
    "The mean (represented by the greek letter mu— μ) is the average of a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of the Number is :0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "numbers=[-4,-3,-2,-1,0,1,2,3,4]\n",
    "\n",
    "mean=np.mean(numbers)\n",
    "print(\"The mean of the Number is :{}\".format(mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Median\n",
    "\n",
    "The median is the middle of a dataset. To calculate the median, we sort all the values (in ascending or descending order) and take the one that is in the middle.\n",
    "\n",
    "If there is an even number of data points, then we calculate the mean of the two that fall in the middle.\n",
    "The median is less susceptible to outliers than the mean, and hence we need to take into consideration how the data distribution looks like, to choose which one to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The median of the Number is :0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "numbers=[-4,-3,-2,-1,0,1,2,3,4]\n",
    "\n",
    "median=np.median(numbers)\n",
    "print(\"The median of the Number is :{}\".format(median))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mode\n",
    "\n",
    "The mode is the most common value in the dataset. To calculate the mode, we locate the number that occurs more frequently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The median of the Number is :[-4]\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "numbers=[-4,-3,-2,-1,0,1,2,3,-4]\n",
    "\n",
    "mode=stats.mode(numbers)\n",
    "print(\"The median of the Number is :{}\".format(mode[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measures of Variability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Range\n",
    "\n",
    "Range is the difference between the lowest and the highest number of a dataset. To calculate the range, we subtract the minimum from the maximum value.\n",
    "It shows us how varied the dataset is, i.e. how spread it is, but again, like mean, it is really sensitive to outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The range of the Number is :8\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "numbers=[-4,-3,-2,-1,0,1,2,3,4]\n",
    "\n",
    "range_data=np.max(numbers)-np.min(numbers)\n",
    "print(\"The range of the Number is :{}\".format(range_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variance\n",
    "\n",
    "Variance measures how spread out the data is. To calculate the variance, we take the average of the squared differences from the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Variance of the Number is :6.666666666666667\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "numbers=[-4,-3,-2,-1,0,1,2,3,4]\n",
    "\n",
    "mean=np.mean(numbers)\n",
    "numbers2=numbers-mean\n",
    "numbers2=np.square(numbers2)\n",
    "variance=np.sum(numbers2)/len(numbers2)\n",
    "print(\"The Variance of the Number is :{}\".format(variance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Deviation\n",
    "\n",
    "Standard deviation (represented by the greek letter sigma — σ) is just the square root of the variance.\n",
    "It is a measure of dispersion in terms of how many standard deviations it is away from the mean, and as we will see in a following article it is used to judge which data point is an outlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Standard Deviation of the Number is :2.581988897471611\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "numbers=[-4,-3,-2,-1,0,1,2,3,4]\n",
    "\n",
    "mean=np.mean(numbers)\n",
    "numbers2=numbers-mean\n",
    "numbers2=np.square(numbers2)\n",
    "variance=np.sum(numbers2)/len(numbers2)\n",
    "std_dev=np.sqrt(variance)\n",
    "print(\"The Standard Deviation of the Number is :{}\".format(std_dev))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability Space\n",
    "\n",
    "In probability theory, a probability space or a probability triple {Omega,F,P} is a mathematical construct that models a real-world process (or “experiment”) consisting of states that occur randomly. A probability space is constructed with a specific kind of situation or experiment in mind. One proposes that each time a situation of that kind arises, the set of possible outcomes is the same and the probabilities are also the same.\n",
    "\n",
    "A probability space consists of three parts:\n",
    "\n",
    "A sample space,Omega which is the set of all possible outcomes.\n",
    "A set of events {F}, where each event is a set containing zero or more outcomes.\n",
    "The assignment of probabilities to the events; that is, a function P from events to probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability Distribution Functions\n",
    "\n",
    "A probability distribution is a function that describes the likelihood of an event or outcome. They come in many shapes, but in only one size: probabilities in a distribution always add up to 1. We will now delve into the different types of distributions, in terms of the dataset being continuous or discrete.\n",
    "\n",
    "\n",
    "## Probability Density Function (PDF)\n",
    "\n",
    "When we see a graph like the one in the figure below, we think that it shows the probability of a given value occurring. However, this is not entirely true for continuous data because there is an infinite number of data points. As such the probability of a specific value happening can be very small — infinitely small!\n",
    "The PDF represents the probability of a given range of values occurring. And hence the word ‘density’! To visualise the probability, we plot the dataset as a curve. The area under the curve between two points corresponds to the probability that the variable falls between those two values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/normaldist.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Between the mean and one standard deviation (1σ) there is 34.1% possibility of a value landing in that range. So for a given value there is 68.2% chance to fall between -1σ and 1σ — which is very likely!!!\n",
    "What this means is that there is a concentration of values near the mean and as we get out beyond the one standard deviations (+-), the probability gets smaller and smaller."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability Mass Function (PMF)\n",
    "When it comes to discrete data, the PMF is the measure that gives us the probability of a given value occurring. To visualise the probability, we plot the dataset as a histogram."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"images/pmf.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Data Distributions\n",
    "\n",
    "## PDF-1: Uniform / Rectangular Distribution\n",
    "\n",
    "A uniform distribution means there is a flat constant probability of a value occurring within a given range, and is concerned with events that are equally likely to occur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"images/ud.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF-2: Normal / Gaussian Distribution\n",
    "\n",
    "We saw a standard normal distribution when we explored what PDF is. If we introduce the ‘random’ element, a normal distribution does not look like a perfect curve, but more like the following example.\n",
    "The mean for the standard normal distribution is zero, and the standard deviation is one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"images/nd.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF-3: T Distribution\n",
    "T or Student’s T distribution looks a lot like the bell shaped curve of a normal distribution, but is a bit shorter and with heavier tails. It is used (instead of the normal distribution) when we have small samples and/or when the population variance is unknown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/td.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PMF-4: Chi-Square Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "__The chi-square (χ²) distribution is used to assess a series of problems:__\n",
    "\n",
    "- whether a data set fits a particular distribution\n",
    "- whether the distributions of two populations are the same\n",
    "- whether two events might be independent\n",
    "- whether there is a different variability within a population.\n",
    "- The curve is skewed to the right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"images/chi.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measures of Location\n",
    "\n",
    "## Percentiles\n",
    "Percentiles divide ordered data into hundredths. In a sorted dataset, a given percentile is the point at which that percent of the data is less than the point we are at.\n",
    "\n",
    "\n",
    "## Quartiles\n",
    "Quartiles are special percentiles, which divide the data into quarters. The first quartile, Q1, is the same as the 25th percentile, and the third quartile, Q3, is the same as the 75th percentile. The median is called both the second quartile, Q2, and the 50th percentile.\n",
    "\n",
    "\n",
    "## Interquartile Range (IQR)\n",
    "The IQR is a number that indicates how spread the middle half (i.e. the middle 50%) of the dataset is and can help determine outliers. It is the difference between the Q3 and Q1.\n",
    "\n",
    "__Generally speaking, outliers are those data points that fall outside from the Q1 – 1.5 x IQR and Q3 + 1.5 x IQR range.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moments\n",
    "Moments describe various aspects of the nature and shape of our distribution.\n",
    "#1 — The first moment is the mean of the data, which describes the location of the distribution.\n",
    "#2 — The second moment is the variance, which describes the spread of the distribution. High values are more spread out than smaller values.\n",
    "#3 — The third moment is the skewness and it is basically a measure of how lopsided a distribution is. A positive skew means we have a left lean and a long right tail. This means that the mean is to the right of the bulk of our data. And vice versa:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"images/skewness.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#4 — The fourth moment is the kurtosis, which describes how thick the tail is and how sharp the peak is. It indicates how likely it is to find extreme values in our data. Higher values make outliers more likely. This sounds a lot like spread (variance) but is subtly different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"images/kurt.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction tp Covariance and Corelation\n",
    "\n",
    "To lay the basis for this article, we will assume we have a scatterplot and each data point represents a person: their professional experience in years on one axis versus their income on another."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/corelation.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covariance\n",
    "Covariance is a measure of association between two (or more) random variables.\n",
    "As the name ‘co + variance’ implies, it is like the variance, but applied to a comparison of two variables — in place of the sum of squares, we have a sum of cross-products.\n",
    "While Variance tells us how a single variable varies from the mean; Covariance tells us how two variables vary from each other. As such it’s fair to say:\n",
    "Covariance is measuring the Variance between two variables.\n",
    "Covariance can be negative or positive (or zero obviously): A positive value means that the two variables tend to vary in the same direction (i.e. if one increases, then the other one increases too), a negative value means that they vary in opposite directions (i.e. if one increases, then the other one decreases), and zero means that they don’t vary together.\n",
    "\n",
    "### Formula\n",
    "The formula might be hard to interpret, but it is more important to understand what it means:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"images/cova.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we think that the dataset of a random variable is represented as a vector, then in the previous example, we have two vectors for experience and income. Here are the steps we need to follow:\n",
    "#1. Convert these two vectors to vectors of variances from the mean.\n",
    "#2. Take the dot product of the two vectors (which is equal to the cosine of the angle between them).\n",
    "#3. Divide by the sample size (n or n - 1, as discussed before, based on whether it is full population or not).\n",
    "On the 2nd step, we effectively measure the angle between these two vectors, so if they are close to each other, it means that these variables are tightly coupled.\n",
    "## Main Limitation\n",
    "It is important to note that while the Covariance does measure the directional relationship between two variables, it does not show the strength of the relationship between them.\n",
    "In practice, the biggest problem with this metric is that it depends on the units used. For example, if we were to convert the years of experience into months of experience, then the Covariance would be 12 times larger!\n",
    "This is where Correlation comes in!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation\n",
    "\n",
    "The Correlation is one of the most common metrics in Statistics that describes the degree of relationship between two random variables. It is considered to be the normalised version of the Covariance. Let’s see why…\n",
    "## Formula\n",
    "The Correlation (represented by the Greek letter ρ — rho) can be expressed using this formula:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/corel.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The correlation is bounded between -1 and 1. Like the Covariance, the sign of the Correlation indicates the direction of the relationship: positive means that random variables move together, negative means that random variables move in different directions.\n",
    "- The endpoints (i.e. 1 and -1) indicate that there is a perfect relationship between the two variables. For instance, the relationship between meters and centimetres is always that 1m corresponds to 100cm. If we plot this relationship it will be a perfect line, and therefore the Correlation is 1.\n",
    "- _Please note that a perfect relationship is pretty rare in real life data, since two random variables don’t usually map to each other by a constant factor.\n",
    "- _A Correlation of 0 means that there is no linear relationship between the two variables. There might be a x = y² relationship.\n",
    "### Key Characteristics\n",
    "The Correlation does not only indicate the direction of the relationship but also its strength, (depending on how big the absolute value is) as it is unitless: Since we divided the Covariance by the Standard Deviation, the units were cancelled out.\n",
    "Finally, we need to remember that ‘Correlation does not imply Causation’: a high correlation between two random variables just means that they are associated with each other, but their relationship is not necessarily causal in nature. The only way to prove causation is with controlled experiments, where we eliminate outside variables and isolate the effects of the two variables in question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional Probability\n",
    "\n",
    "Conditional probability is the likelihood of an event occurring, based on the occurrence of a previous event.\n",
    "The notation for conditional probability is P(A|B), read as ‘the probability of A given B’. The formula for conditional probability is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"images/condp.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayes’ Theorem\n",
    "\n",
    "Having just explored what the Conditional Probability is, let’s take a look at the Bayes’ Theorem. It simply says:\n",
    "The probability of A given B is equal to the probability of B given A times the probability of A, over the probability of B."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"images/bayes.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Hypothesis testing is a critical tool in inferential statistics, for determining what the value of a population parameter could be. We often draw this conclusion based on a sample data analysis.\n",
    "\n",
    "With the advent of data-driven decision making in business, science, technology, social, and political undertakings, the concept of hypothesis testing has become critically important to understand and apply in the right context.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypothesis Testing\n",
    "Hypothesis testing was introduced by Ronald Fisher, Jerzy Neyman, Karl Pearson and Pearson’s son, Egon Pearson.   Hypothesis testing is a statistical method that is used in making statistical decisions using experimental data.  Hypothesis Testing is basically an assumption that we make about the population parameter.\n",
    "__Key terms and concepts:__\n",
    "\n",
    "- __Null hypothesis__: Null hypothesis is a statistical hypothesis that assumes that the observation is due to a chance factor.  Null hypothesis is denoted by; H0: μ1 = μ2, which shows that there is no difference between the two population means.\n",
    "- __Alternative hypothesis__: Contrary to the null hypothesis, the alternative hypothesis shows that observations are the result of a real effect.\n",
    "- __Level of significance__: Refers to the degree of significance in which we accept or reject the null-hypothesis.  100% accuracy is not possible for accepting or rejecting a hypothesis, so we therefore select a level of significance that is usually 5%.\n",
    "- __Type I error__: When we reject the null hypothesis, although that hypothesis was true.  Type I error is denoted by alpha.  In hypothesis testing, the normal curve that shows the critical region is called the alpha region.\n",
    "- __Type II errors__: When we accept the null hypothesis but it is false.  Type II errors are denoted by beta.  In Hypothesis testing, the normal curve that shows the acceptance region is called the beta region.\n",
    "- __Power__: Usually known as the probability of correctly accepting the null hypothesis.  1-beta is called power of the analysis.\n",
    "- __One-tailed test__: When the given statistical hypothesis is one value like H0: μ1 = μ2, it is called the one-tailed test.\n",
    "- __Two-tailed test__: When the given statistics hypothesis assumes a less than or greater than value, it is called the two-tailed test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.statisticshowto.datasciencecentral.com/probability-and-statistics/hypothesis-testing/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
